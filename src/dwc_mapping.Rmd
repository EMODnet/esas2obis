---
title: "Darwin Core mapping of ESAS data"
author:
- Peter Desmet
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
---

This document describes how (and contains the code to) transform European Seabirds at Sea (ESAS) data to an [OBIS-ENV Darwin Core Archive](https://obis.org/manual/dataformat/#obis-env-data) that can be uploaded to an IPT.

# Setup 

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = TRUE)
```

Install required libraries (if not yet installed):

```{r}
installed <- rownames(installed.packages())
required <- c("magrittr", "here", "glue", "jsonlite", "readr", "tidyr", "DBI", "icesVocab")
if (!all(required %in% installed)) {
  install.packages(required[!required %in% installed])
}
```

Load libraries:

```{r message = FALSE}
library(magrittr)       # To use pipes
library(here)           # To find files
library(glue)           # To insert variables in strings
library(jsonlite)       # To read JSON
library(readr)          # To write files
library(tidyr)          # To tidy data
library(DBI)            # To create and query databases
library(icesVocab)      # To get code lists
```

# Read source data

Read public data from the [ESAS web services](https://esas.ices.dk/webservices):

```{r}
# Note that fromJSON will return the data as a data frame (simplifyDataframe = TRUE)
campaigns <- fromJSON("https://esas.ices.dk/api/getCampaignRecords")
samples <- fromJSON("https://esas.ices.dk/api/getSampleRecords")
positions <- fromJSON("https://esas.ices.dk/api/getPositionRecords")
observations <- fromJSON("https://esas.ices.dk/api/getObservationRecords")
```

Set all columns to character to avoid date interpretation issues in SQLite (see https://stackoverflow.com/a/13462536/2463806)

```{r}
campaigns <- mutate(campaigns, across(everything(), as.character))
samples <- mutate(samples, across(everything(), as.character))
positions <- mutate(positions, across(everything(), as.character))
observations <- mutate(observations, across(everything(), as.character))
```

Restrict campaigns to public ones:

```{r}
campaigns <- campaigns %>% filter(dataAccess == "Public")
```

Separate `~` delimited values in `association` and `behaviour` into multiple rows:

```{r}
# obs | association  ->  obs | association
# 1   | A~B              1   | A
#                        1   | B

observations <- tidyr::separate_rows(
  observations,
  association, behaviour, # This column names are case sensitive
  sep = "~"
)
```

## Read code lists

Load ESAS species list from GitHub repository:

```{r}
species <- readr::read_tsv("https://raw.githubusercontent.com/ices-tools-dev/esas/main/_data/vocabularies/species.tsv", col_types = "iccicicc")
```

Get code lists from ICES vocabularies API:

```{r}
shipc <- getCodeList("SHIPC")
platformclass <- getCodeList(URLencode("Platform Class"))
platformside <- getCodeList("PlatformSide")
bdcountmethod <- getCodeList("BD_CountMethod")
targettaxa <- getCodeList("TargetTaxa")
useofbinoculars <- getCodeList("UseOfBinoculars")
beaufort <- getCodeList("Beaufort")
visibility <- getCodeList("Visibility")
glare <- getCodeList("Glare")
cloudcover <- getCodeList("CloudCover")
precipitation <- getCodeList("Precipitation")
sightability <- getCodeList("Sightability")
observationdistance <- getCodeList("ObservationDistance")
lifestage <- getCodeList("LifeStage")
moult <- getCodeList("Moult")
plumage <- getCodeList("Plumage")
sex <- getCodeList("SEXCO")
traveldirection <- getCodeList("TravelDirection")
preytype <- getCodeList("PreyType")
association <- getCodeList("Association")
behaviour <- getCodeList("Behaviour")
```

## Create database

Create a SQLite database with the source data and code lists, so it can be queried with SQL in the next steps:

```{r}
con <- DBI::dbConnect(RSQLite::SQLite(), ":memory:")

# Import data
DBI::dbWriteTable(con, "campaigns", campaigns)
DBI::dbWriteTable(con, "samples", samples)
DBI::dbWriteTable(con, "positions", positions)
DBI::dbWriteTable(con, "observations", observations)

# Import code lists
DBI::dbWriteTable(con, "species", species)
DBI::dbWriteTable(con, "shipc", shipc)
DBI::dbWriteTable(con, "platformclass", platformclass)
DBI::dbWriteTable(con, "platformside", platformside)
DBI::dbWriteTable(con, "bdcountmethod", bdcountmethod)
DBI::dbWriteTable(con, "targettaxa", targettaxa)
DBI::dbWriteTable(con, "useofbinoculars", useofbinoculars)
DBI::dbWriteTable(con, "beaufort", beaufort)
DBI::dbWriteTable(con, "visibility", visibility)
DBI::dbWriteTable(con, "glare", glare)
DBI::dbWriteTable(con, "cloudcover", cloudcover)
DBI::dbWriteTable(con, "precipitation", precipitation)
DBI::dbWriteTable(con, "sightability", sightability)
DBI::dbWriteTable(con, "observationdistance", observationdistance)
DBI::dbWriteTable(con, "lifestage", lifestage)
DBI::dbWriteTable(con, "moult", moult)
DBI::dbWriteTable(con, "plumage", plumage)
DBI::dbWriteTable(con, "sex", sex)
DBI::dbWriteTable(con, "traveldirection", traveldirection)
DBI::dbWriteTable(con, "preytype", preytype)
DBI::dbWriteTable(con, "association", association)
DBI::dbWriteTable(con, "behaviour", behaviour)
```

## Darwin Core mapping

The Darwin Core mapping follows the recommendations of the [OBIS Darwin Core manual](https://obis.org/manual/darwincore/) and is structured as [OBIS-ENV-DATA](https://obis.org/manual/dataformat/#obis-env-data).

Create [Event](https://rs.gbif.org/core/dwc_event_2022-02-02.xml) core:

```{r}
dwc_event_sql <- glue::glue_sql(readr::read_file(here::here("sql", "dwc_event.sql")), .con = con)
dwc_event <- DBI::dbGetQuery(con, dwc_event_sql)
```

Create [Occurrence](https://rs.gbif.org/core/dwc_occurrence_2022-02-02.xml) extension:

```{r}
dwc_occurrence_sql <- glue::glue_sql(readr::read_file(here::here("sql", "dwc_occurrence.sql")), .con = con)
dwc_occurrence <- DBI::dbGetQuery(con, dwc_occurrence_sql)
```

Create [Extended Measurement Or Facts](https://rs.gbif.org/extension/obis/extended_measurement_or_fact.xml) extension:

```{r}
dwc_emof_sql <- glue::glue_sql(readr::read_file(here::here("sql", "dwc_emof.sql")), .con = con)
dwc_emof <- DBI::dbGetQuery(con, dwc_emof_sql)
```

## Save data to CSV

Save all data, to be used for IPT upload:

```{r}
directory <- here::here("data", "processed")
if (!dir.exists(directory)) { dir.create(directory) }
write_csv(dwc_event, file.path(directory, "event.csv"), na = "")
write_csv(dwc_occurrence, file.path(directory, "occurrence.csv"), na = "")
write_csv(dwc_emof, file.path(directory, "emof.csv"), na = "")
```

Save a sample of the data, to be used in git to notice mapping issues:

```{r}
# Filter data on a single campaign
campaign_id <- "110000153"
dwc_event_sample <- dwc_event %>% filter(grepl(campaign_id, eventID))
dwc_occurrence_sample <- dwc_occurrence %>% filter(grepl(campaign_id, eventID))
dwc_emof_sample <- dwc_emof %>% filter(grepl(campaign_id, eventID))

# Write data
directory <- here::here("data", "processed_sample")
write_csv(dwc_event_sample, file.path(directory, "event.csv"), na = "")
write_csv(dwc_occurrence_sample, file.path(directory, "occurrence.csv"), na = "")
write_csv(dwc_emof_sample, file.path(directory, "emof.csv"), na = "")
```
